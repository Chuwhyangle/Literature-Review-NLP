@inproceedings{agarwalPromptWizardOptimizingPrompts2025,
  title = {{{PromptWizard}}: {{Optimizing Prompts}} via {{Task-Aware}}, {{Feedback-Driven Self-Evolution}}},
  shorttitle = {{{PromptWizard}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2025},
  author = {Agarwal, Eshaan and Magazine, Raghav and Singh, Joykirat and Dani, Vivek and Ganu, Tanuja and Nambi, Akshay},
  editor = {Che, Wanxiang and Nabende, Joyce and Shutova, Ekaterina and Pilehvar, Mohammad Taher},
  year = {2025},
  month = jul,
  pages = {19974--20003},
  publisher = {Association for Computational Linguistics},
  address = {Vienna, Austria},
  doi = {10.18653/v1/2025.findings-acl.1025},
  urldate = {2025-10-07},
  abstract = {Large language models (LLMs) have transformed AI across diverse domains, with prompting being central to their success in guiding model outputs. However, manual prompt engineering is both labor-intensive and domain-specific, necessitating the need for automated solutions. We introduce PromptWizard, a novel, fully automated framework for discrete prompt optimization, utilizing a self-evolving, self-adapting mechanism. Through a feedback-driven critique and synthesis process, PromptWizard achieves an effective balance between exploration and exploitation, iteratively refining both prompt instructions and in-context examples to generate human-readable, task-specific prompts. This guided approach systematically improves prompt quality, resulting in superior performance across 45 tasks. PromptWizard excels even with limited training data, smaller LLMs, and various LLM architectures. Additionally, our cost analysis reveals a substantial reduction in API calls, token usage, and overall cost, demonstrating PromptWizard's efficiency, scalability, and advantages over existing prompt optimization strategies.},
  isbn = {979-8-89176-256-5},
  annotation = {0 citations (Crossref/DOI) [2025-10-07]},
  file = {C:\Users\dashi\Zotero\storage\4M97PI55\Agarwal 等 - 2025 - PromptWizard Optimizing Prompts via Task-Aware, Feedback-Driven Self-Evolution.pdf}
}

@inproceedings{aswaniAutoEvolveEnhancingLarge2024,
  title = {Auto-{{Evolve}}: {{Enhancing Large Language Model}}'s {{Performance}} via {{Self-Reasoning Framework}}},
  shorttitle = {Auto-{{Evolve}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2024},
  author = {Aswani, Krishna and Lu, Huilin and Patankar, Pranav and Dhalwani, Priya and Tan, Xue and Ganeshmohan, Jayant and Lacasse, Simon},
  editor = {{Al-Onaizan}, Yaser and Bansal, Mohit and Chen, Yun-Nung},
  year = {2024},
  month = nov,
  pages = {13243--13257},
  publisher = {Association for Computational Linguistics},
  address = {Miami, Florida, USA},
  doi = {10.18653/v1/2024.findings-emnlp.774},
  urldate = {2025-10-06},
  abstract = {Recent advancements in prompt engineering strategies, such as Chain-of-Thought (CoT) and Self-Discover, have demonstrated significant potential in improving the reasoning abilities of Large Language Models (LLMs). However, these state-of-the-art (SOTA) prompting strategies rely on a fixed set of static seed reasoning modules like ``think step by step'' or ``break down this problem'' intended to simulate human approach to problem-solving. This constraint limits the flexibility of models in tackling diverse problems effectively. In this paper, we introduce Auto-Evolve, a novel framework that enables LLMs to self-create dynamic reasoning modules and downstream action plan, resulting in significant improvements over current SOTA methods. We evaluate Auto-Evolve on the challenging BigBench-Hard (BBH) dataset with Claude 2.0, Claude 3 Sonnet, Mistral Large, and GPT-4, where it consistently outperforms the SOTA prompt strategies. Auto-Evolve outperforms CoT by up to 10.4\% and on an average by 7\% across these four models. Our framework introduces two innovations: a) Auto-Evolve dynamically generates reasoning modules for each task while aligning with human reasoning paradigm, thus eliminating the need for predefined templates. b) An iterative refinement component, that incrementally refines instruction guidance for LLMs and helps boost performance by average 2.8\% compared to doing it in a single step.},
  annotation = {0 citations (Crossref/DOI) [2025-10-06]},
  file = {C:\Users\dashi\Zotero\storage\9JXXVJYP\Aswani 等 - 2024 - Auto-Evolve Enhancing Large Language Model's Performance via Self-Reasoning Framework.pdf}
}

@inproceedings{chuNavigateEnigmaticLabyrinth2024b,
  title = {Navigate through {{Enigmatic Labyrinth A Survey}} of {{Chain}} of {{Thought Reasoning}}: {{Advances}}, {{Frontiers}} and {{Future}}},
  shorttitle = {Navigate through {{Enigmatic Labyrinth A Survey}} of {{Chain}} of {{Thought Reasoning}}},
  booktitle = {Proceedings of the 62nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  year = {2024},
  pages = {1173--1203},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.acl-long.65},
  urldate = {2025-10-04},
  abstract = {Reasoning, a fundamental cognitive process integral to human intelligence, has garnered substantial interest within artificial intelligence. Notably, recent studies have revealed that chainof-thought prompting significantly enhances LLM's reasoning capabilities, which attracts widespread attention from both academics and industry. In this paper, we systematically investigate relevant research, summarizing advanced methods through a meticulous taxonomy that offers novel perspectives. Moreover, we delve into the current frontiers and delineate the challenges and future directions, thereby shedding light on future research. Furthermore, we engage in a discussion about open questions. We hope this paper serves as an introduction for beginners and fosters future research. Resources have been made publicly available at https://github.com/zchuz/CoTReasoning-Survey.},
  langid = {english},
  annotation = {16 citations (Crossref/DOI) [2025-10-04]\\
TLDR: This paper systematically investigate relevant research, summarizing advanced methods through a meticulous taxonomy that offers novel perspectives, and delve into the current frontiers and delineate the challenges and future directions, thereby shedding light on future research.},
  file = {C:\Users\dashi\Zotero\storage\RLKC6QVJ\Chu 等 - 2024 - Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning Advances, Frontiers and.pdf}
}

@misc{cobbeTrainingVerifiersSolve2021,
  title = {Training {{Verifiers}} to {{Solve Math Word Problems}}},
  author = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  year = {2021},
  month = nov,
  number = {arXiv:2110.14168},
  eprint = {2110.14168},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.14168},
  urldate = {2025-10-07},
  abstract = {State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\XJFFYJ3G\\Cobbe 等 - 2021 - Training Verifiers to Solve Math Word Problems.pdf;C\:\\Users\\dashi\\Zotero\\storage\\LGZTJSSA\\2110.html}
}

@inproceedings{dengProductQuestionAnswering2023,
  title = {Product {{Question Answering}} in {{E-Commerce}}: {{A Survey}}},
  shorttitle = {Product {{Question Answering}} in {{E-Commerce}}},
  booktitle = {Proceedings of the 61st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Deng, Yang and Zhang, Wenxuan and Yu, Qian and Lam, Wai},
  year = {2023},
  pages = {11951--11964},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.667},
  urldate = {2025-10-03},
  abstract = {Product question answering (PQA), aiming to automatically provide instant responses to customer's questions in E-Commerce platforms, has drawn increasing attention in recent years. Compared with typical QA problems, PQA exhibits unique challenges such as the subjectivity and reliability of user-generated contents in Ecommerce platforms. Therefore, various problem settings and novel methods have been proposed to capture these special characteristics. In this paper, we aim to systematically review existing research efforts on PQA. Specifically, we categorize PQA studies into four problem settings in terms of the form of provided answers. We analyze the pros and cons, as well as present existing datasets and evaluation protocols for each setting. We further summarize the most significant challenges that characterize PQA from general QA applications and discuss their corresponding solutions. Finally, we conclude this paper by providing the prospect on several future directions.},
  langid = {english},
  annotation = {4 citations (Crossref/DOI) [2025-10-03]},
  file = {C:\Users\dashi\Zotero\storage\U9KM3VJ6\Deng 等 - 2023 - Product Question Answering in E-Commerce A Survey.pdf}
}

@misc{gaoRetrievalAugmentedGenerationLarge2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  year = {2024},
  month = mar,
  number = {arXiv:2312.10997},
  eprint = {2312.10997},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10997},
  urldate = {2025-10-03},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domainspecific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-theart technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development 1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {TLDR: This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG, and meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques.},
  file = {C:\Users\dashi\Zotero\storage\LP3GFVSU\Gao 等 - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf}
}

@article{huangReasoningLargeLanguage,
  title = {Towards {{Reasoning}} in {{Large Language Models}}: {{A Survey}}},
  author = {Huang, Jie and Chang, Kevin Chen-Chuan},
  langid = {english},
  file = {C:\Users\dashi\Zotero\storage\T6X83BB7\Huang和Chang - Towards Reasoning in Large Language Models A Survey.pdf}
}

@inproceedings{jinSelfHarmonizedChainThought2025,
  title = {Self-{{Harmonized Chain}} of {{Thought}}},
  booktitle = {Proceedings of the 2025 {{Conference}} of the {{Nations}} of the {{Americas Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}} ({{Volume}} 1: {{Long Papers}})},
  author = {Jin, Ziqi and Lu, Wei},
  editor = {Chiruzzo, Luis and Ritter, Alan and Wang, Lu},
  year = {2025},
  month = apr,
  pages = {1153--1174},
  publisher = {Association for Computational Linguistics},
  address = {Albuquerque, New Mexico},
  doi = {10.18653/v1/2025.naacl-long.53},
  urldate = {2025-10-06},
  abstract = {Chain-of-thought (CoT) prompting has demonstrated the capacity of large language models to perform complex reasoning through intermediate steps. While effective, current CoT methods face challenges: Zero-shot-CoT can lead to reasoning errors, and Few-shot-CoT requires labor-intensive manual demonstrations. Auto-CoT attempts to address these issues by automatically generating diverse demonstrations, but this diversity can lead to inconsistent reasoning patterns. We propose ECHO (Self-Harmonized Chain of Thought), a novel method that unifies diverse solution paths into a consistent and effective reasoning pattern. ECHO employs an iterative process to refine and harmonize automatically generated demonstrations, mitigating the limitations of existing approaches. Our comprehensive experiments across arithmetic, commonsense, and symbolic reasoning tasks demonstrate that ECHO outperforms Auto-CoT by an average of 2.8\%. These findings suggest that ECHO represents a significant step towards more robust and generalizable automated reasoning in large language models.},
  isbn = {979-8-89176-189-6},
  langid = {american},
  annotation = {2 citations (Crossref/DOI) [2025-10-06]},
  file = {C:\Users\dashi\Zotero\storage\JPMLD673\Jin和Lu - 2025 - Self-Harmonized Chain of Thought.pdf}
}

@misc{luSurveyDeepLearning2023a,
  title = {A {{Survey}} of {{Deep Learning}} for {{Mathematical Reasoning}}},
  author = {Lu, Pan and Qiu, Liang and Yu, Wenhao and Welleck, Sean and Chang, Kai-Wei},
  year = {2023},
  month = jun,
  number = {arXiv:2212.10535},
  eprint = {2212.10535},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.10535},
  urldate = {2025-10-07},
  abstract = {Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  annotation = {TLDR: This survey paper reviews the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade, and evaluates existing benchmarks and methods and discusses future research directions in this domain.},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\GDPWT2UD\\Lu 等 - 2023 - A Survey of Deep Learning for Mathematical Reasoning.pdf;C\:\\Users\\dashi\\Zotero\\storage\\8Z2F4I5C\\2212.html}
}

@inproceedings{philippyCommonUnderstandingContributing2023,
  title = {Towards a {{Common Understanding}} of {{Contributing Factors}} for {{Cross-Lingual Transfer}} in {{Multilingual Language Models}}: {{A Review}}},
  shorttitle = {Towards a {{Common Understanding}} of {{Contributing Factors}} for {{Cross-Lingual Transfer}} in {{Multilingual Language Models}}},
  booktitle = {Proceedings of the 61st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Philippy, Fred and Guo, Siwen and Haddadan, Shohreh},
  year = {2023},
  pages = {5877--5891},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.323},
  urldate = {2025-10-03},
  abstract = {In recent years, pre-trained Multilingual Language Models (MLLMs) have shown a strong ability to transfer knowledge across different languages. However, given that the aspiration for such an ability has not been explicitly incorporated in the design of the majority of MLLMs, it is challenging to obtain a unique and straightforward explanation for its emergence. In this review paper, we survey literature that investigates different factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer and subsequently outline and discuss these factors in detail. To enhance the structure of this review and to facilitate consolidation with future studies, we identify five categories of such factors. In addition to providing a summary of empirical evidence from past studies, we identify consensuses among studies with consistent findings and resolve conflicts among contradictory ones. Our work contextualizes and unifies existing research streams which aim at explaining the cross-lingual potential of MLLMs. This review provides, first, an aligned reference point for future research and, second, guidance for a better-informed and more efficient way of leveraging the crosslingual capacity of MLLMs.},
  langid = {english},
  annotation = {4 citations (Crossref/DOI) [2025-10-03]},
  file = {C:\Users\dashi\Zotero\storage\3TIGY8J6\Philippy 等 - 2023 - Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual La.pdf}
}

@misc{plaatMultiStepReasoningLarge2025,
  title = {Multi-{{Step Reasoning}} with {{Large Language Models}}, a {{Survey}}},
  author = {Plaat, Aske and Wong, Annie and Verberne, Suzan and Broekens, Joost and van Stein, Niki and Back, Thomas},
  year = {2025},
  month = aug,
  number = {arXiv:2407.11511},
  eprint = {2407.11511},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.11511},
  urldate = {2025-10-06},
  abstract = {Language models with billions of parameters exhibit in-context learning abilities, enabling few-shot learning on tasks that the model was not specifically trained for. Traditional models achieve breakthrough performance on language tasks, but do not perform well on basic reasoning benchmarks. However, a new in-context learning approach, Chain-of-thought, has demonstrated strong multi-step reasoning abilities on these benchmarks. The research on LLM reasoning abilities started with the question whether LLMs can solve grade school math word problems, and has expanded to other tasks in the past few years. This paper reviews the field of multi-step reasoning with LLMs. We propose a taxonomy that identifies different ways to generate, evaluate, and control multi-step reasoning. We provide an in-depth coverage of core approaches and open problems, and we propose a research agenda for the near future. We find that multi-step reasoning approaches have progressed beyond math word problems, and can now successfully solve challenges in logic, combinatorial games, and robotics, sometimes by first generating code that is then executed by external tools. Many studies in multi-step methods are using reinforcement learning for finetuning, external optimization loops, in context reinforcement learning, and self-reflection.},
  archiveprefix = {arXiv},
  langid = {american},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\LEI3QQNC\\Plaat 等 - 2025 - Multi-Step Reasoning with Large Language Models, a Survey.pdf;C\:\\Users\\dashi\\Zotero\\storage\\F2ALGKX4\\2407.html}
}

@article{plyusninAdvancesNL2SQLLeveraging,
  title = {Advances in {{NL2SQL}}: {{Leveraging Large Language Models}} for {{Enhanced Query-to-SQL Translation}}},
  author = {Plyusnin, Vladislav},
  abstract = {Converting natural language queries into SQL poses significant challenges in query interpretation, schema comprehension, and precise SQL generation. This task has evolved from rule-based systems to neural networks, and more recently, to advanced large language models. The LLMs have significantly enhanced the accuracy, scalability, and adaptability of NL2SQL systems. This review provides a comprehensive analysis of LLM-powered NL2SQL approaches, focusing on translation methods, in-context learning, fine-tuning, and post-processing techniques. Key evaluation metrics are discussed, emphasizing the difficulty of handling complex queries, multi-table schemas, and ambiguous language. The paper identifies future research priorities, including the development of cost-effective, scalable, and trustworthy NL2SQL systems that can function across diverse domains and heterogeneous databases, while optimizing computational efficiency and ensuring data privacy.},
  langid = {english},
  file = {C:\Users\dashi\Zotero\storage\AQXAGSLN\Plyusnin - Advances in NL2SQL Leveraging Large Language Models for Enhanced Query-to-SQL Translation.pdf}
}

@article{revellMethodsAddressCauses,
  title = {Methods to {{Address}} the {{Causes}} of {{Hallucinations}} in {{Large Language Models}} - {{A Survey}}},
  author = {Revell, Andrew},
  abstract = {Large language models (LLMs) have shown remarkable capabilities in natural language processing, but their tendency to generate hallucinations---unfaithful or factually incorrect content---poses significant challenges for reliable practical applications. This paper analyses current methods addressing the causes of hallucinations in LLMs, examining approaches across the model lifecycle including data, architectural improvements, training method, alignment techniques, and inference strategies. We identify critical gaps in the application of standardised evaluation methods to guide understanding of trade-offs between the methods to address hallucinations.},
  langid = {english},
  file = {C:\Users\dashi\Zotero\storage\HK3E4MA7\Revell - Methods to Address the Causes of Hallucinations in Large Language Models - A Survey.pdf}
}

@misc{shaoSyntheticPromptingGenerating2023,
  title = {Synthetic {{Prompting}}: {{Generating Chain-of-Thought Demonstrations}} for {{Large Language Models}}},
  shorttitle = {Synthetic {{Prompting}}},
  author = {Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  year = {2023},
  month = feb,
  number = {arXiv:2302.00618},
  eprint = {2302.00618},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.00618},
  urldate = {2025-10-07},
  abstract = {Large language models can perform various reasoning tasks by using chain-of-thought prompting, which guides them to find answers through step-by-step demonstrations. However, the quality of the prompts depends on the demonstrations given to the models, and creating many of them by hand is costly. We introduce Synthetic prompting, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning. Our method alternates between a backward and forward process to generate new examples. The backward process generates a question that match a sampled reasoning chain, so that the question is solvable and clear. The forward process produces a more detailed reasoning chain for the question, improving the quality of the example. We evaluate our method on numerical, symbolic, and algorithmic reasoning tasks, and show that it outperforms existing prompting techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  annotation = {TLDR: Synthetic prompting is introduced, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning.},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\JW6NCX7N\\Shao 等 - 2023 - Synthetic Prompting Generating Chain-of-Thought Demonstrations for Large Language Models.pdf;C\:\\Users\\dashi\\Zotero\\storage\\W3G2K7ZV\\2302.html}
}

@misc{weiChainofThoughtPromptingElicits2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  year = {2023},
  month = jan,
  number = {arXiv:2201.11903},
  eprint = {2201.11903},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.11903},
  urldate = {2025-10-06},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\GU8LZCG7\\Wei 等 - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf;C\:\\Users\\dashi\\Zotero\\storage\\QIX2SVGQ\\2201.html}
}

@misc{wengLargeLanguageModels2023,
  title = {Large {{Language Models}} Are {{Better Reasoners}} with {{Self-Verification}}},
  author = {Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Shengping and Sun, Bin and Liu, Kang and Zhao, Jun},
  year = {2023},
  month = oct,
  number = {arXiv:2212.09561},
  eprint = {2212.09561},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2212.09561},
  urldate = {2025-10-07},
  abstract = {Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: https://github.com/WENGSYX/Self-Verification.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {TLDR: This work proposes a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked, and calculates an explainable verification score based on the accuracy.},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\BNWF4XSP\\Weng 等 - 2023 - Large Language Models are Better Reasoners with Self-Verification.pdf;C\:\\Users\\dashi\\Zotero\\storage\\93LJB73C\\2212.html}
}

@misc{yuBetterChainofThoughtPrompting2023,
  title = {Towards {{Better Chain-of-Thought Prompting Strategies}}: {{A Survey}}},
  shorttitle = {Towards {{Better Chain-of-Thought Prompting Strategies}}},
  author = {Yu, Zihan and He, Liang and Wu, Zhen and Dai, Xinyu and Chen, Jiajun},
  year = {2023},
  month = oct,
  number = {arXiv:2310.04959},
  eprint = {2310.04959},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.04959},
  urldate = {2025-10-06},
  abstract = {Chain-of-Thought (CoT), a step-wise and coherent reasoning chain, shows its impressive strength when used as a prompting strategy for large language models (LLM). Recent years, the prominent effect of CoT prompting has attracted emerging research. However, there still lacks of a systematic summary about key factors of CoT prompting and comprehensive guide for prompts utilizing. For a deeper understanding about CoT prompting, we survey on a wide range of current research, presenting a systematic and comprehensive analysis on several factors that may influence the effect of CoT prompting, and introduce how to better apply it in different applications under these discussions. We further analyze the challenges and propose some future directions about CoT prompting. This survey could provide an overall reference on related research.},
  archiveprefix = {arXiv},
  langid = {american},
  keywords = {Computer Science - Computation and Language},
  annotation = {TLDR: A systematic and comprehensive analysis on several factors that may influence the effect of CoT prompting are presented, and how to better apply it in different applications under these discussions are introduced.},
  file = {C\:\\Users\\dashi\\Zotero\\storage\\6HGJULAQ\\Yu 等 - 2023 - Towards Better Chain-of-Thought Prompting Strategies A Survey.pdf;C\:\\Users\\dashi\\Zotero\\storage\\ESQPQMCN\\2310.html}
}

@article{zhuLargeLanguageModels2025,
  title = {Large {{Language Models}} for {{Information Retrieval}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} for {{Information Retrieval}}},
  author = {Zhu, Yutao and Yuan, Huaying and Wang, Shuting and Liu, Jiongnan and Liu, Wenhan and Deng, Chenlong and Chen, Haonan and Liu, Zheng and Dou, Zhicheng and Wen, Ji-Rong},
  year = {2025},
  month = sep,
  journal = {ACM Transactions on Information Systems},
  eprint = {2308.07107},
  primaryclass = {cs},
  pages = {3748304},
  issn = {1046-8188, 1558-2868},
  doi = {10.1145/3748304},
  urldate = {2025-10-03},
  abstract = {As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  annotation = {5 citations (Crossref/DOI) [2025-10-03]\\
TLDR: This survey delves into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, readers, and search agents.},
  file = {C:\Users\dashi\Zotero\storage\ZFGT4GE4\Zhu 等 - 2025 - Large Language Models for Information Retrieval A Survey.pdf}
}
